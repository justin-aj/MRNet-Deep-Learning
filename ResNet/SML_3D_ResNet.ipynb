{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fXHBVjd3CWir",
        "outputId": "31f3660b-e201-4260-fb50-8356776999c6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "rHx7t_2lB5eu"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "from scipy.ndimage import zoom\n",
        "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
        "import warnings\n",
        "import torchio as tio\n",
        "from torchio import SubjectsLoader\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
        "import torchvision.models as models\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "6zCrIaJmCO1l"
      },
      "outputs": [],
      "source": [
        "# Define paths based on your directory structure\n",
        "main_dir = \"/content/drive/My Drive/DATASET_MRNET/MRNet-v1.0\"\n",
        "train_path = os.path.join(main_dir, \"train\")\n",
        "valid_path = os.path.join(main_dir, \"valid\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "Y49PrVAXCcT2"
      },
      "outputs": [],
      "source": [
        "# Load labels from CSV files\n",
        "train_abnormal = pd.read_csv(os.path.join(main_dir, \"train-abnormal.csv\"), header=None, index_col=0).squeeze(\"columns\").to_dict()\n",
        "train_acl = pd.read_csv(os.path.join(main_dir, \"train-acl.csv\"), header=None, index_col=0).squeeze(\"columns\").to_dict()\n",
        "train_meniscus = pd.read_csv(os.path.join(main_dir, \"train-meniscus.csv\"), header=None, index_col=0).squeeze(\"columns\").to_dict()\n",
        "\n",
        "valid_abnormal = pd.read_csv(os.path.join(main_dir, \"valid-abnormal.csv\"), header=None, index_col=0).squeeze(\"columns\").to_dict()\n",
        "valid_acl = pd.read_csv(os.path.join(main_dir, \"valid-acl.csv\"), header=None, index_col=0).squeeze(\"columns\").to_dict()\n",
        "valid_meniscus = pd.read_csv(os.path.join(main_dir, \"valid-meniscus.csv\"), header=None, index_col=0).squeeze(\"columns\").to_dict()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "QMYpgbOtCcWP"
      },
      "outputs": [],
      "source": [
        "# Function to resize the depth of a scan to a target depth\n",
        "def resize_depth(scan, target_depth):\n",
        "    depth_factor = target_depth / scan.shape[0]\n",
        "    return zoom(scan, (depth_factor, 1, 1), order=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "4VREJuQnCcYk"
      },
      "outputs": [],
      "source": [
        "# Function to pad a scan to a target shape\n",
        "def pad_to_shape(scan, target_shape):\n",
        "    padded_scan = np.zeros(target_shape, dtype=scan.dtype)\n",
        "    min_d, min_h, min_w = min(scan.shape[0], target_shape[0]), min(scan.shape[1], target_shape[1]), min(scan.shape[2], target_shape[2])\n",
        "    padded_scan[:min_d, :min_h, :min_w] = scan[:min_d, :min_h, :min_w]\n",
        "    return padded_scan"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "tKUlb1OHCcbL"
      },
      "outputs": [],
      "source": [
        "# Function to load a specific range of MRI data with labels\n",
        "\n",
        "def load_mri_data(data_type=\"train\", start_idx=0, end_idx=9, target_shape=(48, 256, 256), target_depth=48):\n",
        "    \"\"\"\n",
        "    Loads MRI data from a specified range and resizes/pads each scan to a target shape.\n",
        "    Parameters:\n",
        "    - data_type: \"train\" or \"valid\"\n",
        "    - start_idx, end_idx: Range of file indices to load (e.g., 0 to 9 for train, 1130 to 1249 for valid)\n",
        "    - target_shape: Target shape for each scan after resizing and padding\n",
        "    - target_depth: Target depth for each scan to ensure consistent depth\n",
        "    \"\"\"\n",
        "    # Set data path and range\n",
        "    data_path = train_path if data_type == \"train\" else valid_path\n",
        "    axial_path, coronal_path, sagittal_path = Path(data_path) / \"axial\", Path(data_path) / \"coronal\", Path(data_path) / \"sagittal\"\n",
        "\n",
        "    # Select the appropriate labels dictionary based on data type\n",
        "    abnormal_labels = train_abnormal if data_type == \"train\" else valid_abnormal\n",
        "    acl_labels = train_acl if data_type == \"train\" else valid_acl\n",
        "    meniscus_labels = train_meniscus if data_type == \"train\" else valid_meniscus\n",
        "\n",
        "    # Initialize lists to store data and labels\n",
        "    mri_data, labels = [], []\n",
        "\n",
        "    # Load each MRI scan within the specified range\n",
        "    for i in range(start_idx, end_idx + 1):\n",
        "        # Generate file name with zero-padded format (e.g., 0000, 0001, ...)\n",
        "        file_name = f\"{i:04}.npy\"\n",
        "\n",
        "        # Load and process each view with resizing and padding\n",
        "        axial_scan = pad_to_shape(resize_depth(np.load(axial_path / file_name), target_depth), target_shape)\n",
        "        coronal_scan = pad_to_shape(resize_depth(np.load(coronal_path / file_name), target_depth), target_shape)\n",
        "        sagittal_scan = pad_to_shape(resize_depth(np.load(sagittal_path / file_name), target_depth), target_shape)\n",
        "\n",
        "        # Combine the three views into one structure (3, depth, height, width)\n",
        "        combined_scan = np.stack([axial_scan, coronal_scan, sagittal_scan], axis=0)\n",
        "        mri_data.append(combined_scan)\n",
        "\n",
        "        # Retrieve actual labels for the current scan\n",
        "        abnormal_label = abnormal_labels.get(i, 0)  # Default to 0 if label is missing\n",
        "        acl_label = acl_labels.get(i, 0)\n",
        "        meniscus_label = meniscus_labels.get(i, 0)\n",
        "\n",
        "        # Append the actual labels\n",
        "        labels.append({\"abnormal\": abnormal_label, \"acl\": acl_label, \"meniscus\": meniscus_label})\n",
        "\n",
        "    return np.array(mri_data), labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qcHEhWmwCcdA",
        "outputId": "4d0a6b4b-77fe-44a7-829c-c51908cbe525"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Final training data shape: (1130, 3, 48, 256, 256)\n",
            "Final number of training labels: 1130\n"
          ]
        }
      ],
      "source": [
        "# Define the parameters for batch loading with exact final index coverage\n",
        "start_indices = list(range(0, 1130, 100))\n",
        "end_indices = [min(start + 99, 1129) for start in start_indices]  # Ensure final batch ends at 1129\n",
        "\n",
        "# Function to load a batch of data given start and end indices\n",
        "def load_batch(start, end):\n",
        "    return load_mri_data(data_type=\"train\", start_idx=start, end_idx=end)\n",
        "\n",
        "# Initialize lists to store all data and labels\n",
        "all_data, all_labels = [], []\n",
        "\n",
        "# Use ThreadPoolExecutor to parallelize data loading for all batches\n",
        "with ThreadPoolExecutor() as executor:\n",
        "    # Launch parallel tasks for loading each batch\n",
        "    future_to_indices = {executor.submit(load_batch, start, end): (start, end) for start, end in zip(start_indices, end_indices)}\n",
        "\n",
        "    for future in as_completed(future_to_indices):\n",
        "        data, labels = future.result()\n",
        "        all_data.append(data)\n",
        "        all_labels.extend(labels)  # Extend to add lists of labels directly\n",
        "\n",
        "# Concatenate all data batches into a single array\n",
        "train_data = np.concatenate(all_data, axis=0)\n",
        "train_labels = all_labels  # Already extended to combine all label lists\n",
        "\n",
        "# Check the final shape of training data and labels\n",
        "print(\"Final training data shape:\", train_data.shape)  # Expected: (1130, 3, 48, 256, 256)\n",
        "print(\"Final number of training labels:\", len(train_labels))  # Should match the number of samples in train_data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TAXC9qgrCcfX",
        "outputId": "522b5512-f003-484d-ff57-d5ed25d85de4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation data shape: (120, 3, 48, 256, 256)\n"
          ]
        }
      ],
      "source": [
        "# Load the validation data from indices 1130 to 1249\n",
        "valid_data, valid_labels = load_mri_data(data_type=\"valid\", start_idx=1130, end_idx=1249)\n",
        "\n",
        "# Check data shapes and labels\n",
        "print(\"Validation data shape:\", valid_data.shape)  # Expected: (120, 3, 48, 256, 256)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "uPLH44T9k2Dn"
      },
      "outputs": [],
      "source": [
        "# Define transformations using TorchIO\n",
        "train_transforms = tio.Compose([\n",
        "    tio.RandomFlip(axes=('LR',), flip_probability=0.5, include=('image',)),\n",
        "    tio.ZNormalization(include=('image',)),\n",
        "])\n",
        "\n",
        "valid_transforms = tio.Compose([\n",
        "    tio.ZNormalization(include=('image',)),\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "xeagv35yjwTH"
      },
      "outputs": [],
      "source": [
        "# Prepare subjects for training data\n",
        "train_subjects = []\n",
        "for i in range(len(train_data)):\n",
        "    image_tensor = train_data[i]  # Shape: (C, D, H, W)\n",
        "    label = train_labels[i]\n",
        "    image = tio.ScalarImage(tensor=image_tensor)\n",
        "    subject = tio.Subject(\n",
        "    image=image,\n",
        "    abnormal=label['abnormal'],\n",
        "    acl=label['acl'],\n",
        "    meniscus=label['meniscus']\n",
        "    )\n",
        "    train_subjects.append(subject)\n",
        "\n",
        "# Prepare subjects for validation data\n",
        "valid_subjects = []\n",
        "for i in range(len(valid_data)):\n",
        "    image_tensor = valid_data[i]\n",
        "    label = valid_labels[i]\n",
        "    image = tio.ScalarImage(tensor=image_tensor)\n",
        "    subject = tio.Subject(\n",
        "    image=image,\n",
        "    abnormal=label['abnormal'],\n",
        "    acl=label['acl'],\n",
        "    meniscus=label['meniscus']\n",
        "    )\n",
        "    valid_subjects.append(subject)\n",
        "\n",
        "# Create datasets using tio.SubjectsDataset\n",
        "train_dataset = tio.SubjectsDataset(train_subjects, transform=train_transforms)\n",
        "valid_dataset = tio.SubjectsDataset(valid_subjects, transform=valid_transforms)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "MNWF2yxWk5g5"
      },
      "outputs": [],
      "source": [
        "train_loader = SubjectsLoader(train_dataset, batch_size=2, shuffle=True, num_workers=4)\n",
        "valid_loader = SubjectsLoader(valid_dataset, batch_size=2, shuffle=False, num_workers=4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XkZsSGGYxt79",
        "outputId": "409559f8-cec9-4938-a661-b3681bfe7a6b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'torchio.data.subject.Subject'>\n"
          ]
        }
      ],
      "source": [
        "print(type(train_dataset[0]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "b3cBRUDWk-jz"
      },
      "outputs": [],
      "source": [
        "class MRI3DResNet(nn.Module):\n",
        "    def __init__(self, num_classes=3):\n",
        "        super(MRI3DResNet, self).__init__()\n",
        "        # Load a pretrained 3D ResNet\n",
        "        self.backbone = models.video.r3d_18(pretrained=True)\n",
        "        # Modify the first convolutional layer to accept 3 input channels\n",
        "        self.backbone.stem[0] = nn.Conv3d(\n",
        "            in_channels=3,  # Change to 3 channels\n",
        "            out_channels=64,\n",
        "            kernel_size=(3, 7, 7),\n",
        "            stride=(1, 2, 2),\n",
        "            padding=(1, 3, 3),\n",
        "            bias=False\n",
        "        )\n",
        "        # Replace the fully connected layer\n",
        "        self.backbone.fc = nn.Linear(self.backbone.fc.in_features, num_classes)\n",
        "        # No activation here because we'll use BCEWithLogitsLoss\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.backbone(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "7zsO9CyAlEMu"
      },
      "outputs": [],
      "source": [
        "criterion = nn.BCEWithLogitsLoss()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B05mYPVLlMOl",
        "outputId": "9ccee460-c29e-40d0-fde6-e4314d7cfe41"
      },
      "outputs": [],
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = MRI3DResNet(num_classes=3).to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "XJXMQKEklIyw"
      },
      "outputs": [],
      "source": [
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3, weight_decay=1e-5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "AGR1Hy4n0GjL"
      },
      "outputs": [],
      "source": [
        "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C2ROirPoveEu",
        "outputId": "7797dc38-3d04-4566-b5f0-63d8f85d6e20"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'torchio.data.subject.Subject'>\n"
          ]
        }
      ],
      "source": [
        "print(type(train_subjects[0]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4a1n-eAA2fJf",
        "outputId": "2c28d190-9e0c-4112-8882-23469a374551"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2.5.1+cu121\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "print(torch.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "FXHnRfC03WmK"
      },
      "outputs": [],
      "source": [
        "for name, param in model.named_parameters():\n",
        "    if not param.requires_grad:\n",
        "        print(f\"Parameter {name} does not require gradient\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zYRUMpPslOVM",
        "outputId": "4af240ef-50d3-45ef-9d93-d4376a9e0eb6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "Training Loss: 0.5448, Accuracy: 0.3690, Precision: 0.6314, Recall: 0.6304\n",
            "Validation Loss: 1.7998, Accuracy: 0.2417, Precision: 0.4035, Recall: 0.1741\n",
            "\n",
            "Epoch 2/20\n",
            "Training Loss: 0.5310, Accuracy: 0.3673, Precision: 0.5943, Recall: 0.6192\n",
            "Validation Loss: 0.6786, Accuracy: 0.2250, Precision: 0.6074, Recall: 0.4826\n",
            "\n",
            "Epoch 3/20\n",
            "Training Loss: 0.5303, Accuracy: 0.3726, Precision: 0.5861, Recall: 0.6212\n",
            "Validation Loss: 0.6962, Accuracy: 0.1833, Precision: 0.5896, Recall: 0.4030\n",
            "\n",
            "Epoch 4/20\n",
            "Training Loss: 0.5205, Accuracy: 0.3690, Precision: 0.6059, Recall: 0.6271\n",
            "Validation Loss: 0.7724, Accuracy: 0.3500, Precision: 0.7381, Recall: 0.6915\n",
            "\n",
            "Epoch 5/20\n",
            "Training Loss: 0.5133, Accuracy: 0.3814, Precision: 0.6831, Recall: 0.6469\n",
            "Validation Loss: 0.6772, Accuracy: 0.2000, Precision: 0.7362, Recall: 0.5821\n",
            "\n",
            "Epoch 6/20\n",
            "Training Loss: 0.5123, Accuracy: 0.3708, Precision: 0.6705, Recall: 0.6344\n",
            "Validation Loss: 0.6924, Accuracy: 0.2083, Precision: 0.8128, Recall: 0.5274\n",
            "\n",
            "Epoch 7/20\n",
            "Training Loss: 0.5073, Accuracy: 0.3867, Precision: 0.6706, Recall: 0.6489\n",
            "Validation Loss: 0.7137, Accuracy: 0.2167, Precision: 0.7282, Recall: 0.6468\n",
            "\n",
            "Epoch 8/20\n",
            "Training Loss: 0.5002, Accuracy: 0.3832, Precision: 0.6522, Recall: 0.6331\n",
            "Validation Loss: 0.6368, Accuracy: 0.3167, Precision: 0.7719, Recall: 0.7363\n",
            "\n",
            "Epoch 9/20\n",
            "Training Loss: 0.5065, Accuracy: 0.3796, Precision: 0.6862, Recall: 0.6542\n",
            "Validation Loss: 0.6742, Accuracy: 0.2083, Precision: 0.8099, Recall: 0.5423\n",
            "\n",
            "Epoch 10/20\n",
            "Training Loss: 0.5021, Accuracy: 0.3735, Precision: 0.6955, Recall: 0.6449\n",
            "Validation Loss: 0.6415, Accuracy: 0.1750, Precision: 0.7418, Recall: 0.5721\n",
            "\n",
            "Epoch 11/20\n",
            "Training Loss: 0.4836, Accuracy: 0.3938, Precision: 0.6969, Recall: 0.6798\n",
            "Validation Loss: 0.5906, Accuracy: 0.3250, Precision: 0.7765, Recall: 0.6468\n",
            "\n",
            "Epoch 12/20\n",
            "Training Loss: 0.4977, Accuracy: 0.3894, Precision: 0.6772, Recall: 0.6344\n",
            "Validation Loss: 0.6221, Accuracy: 0.3583, Precision: 0.7552, Recall: 0.7662\n",
            "\n",
            "Epoch 13/20\n",
            "Training Loss: 0.4807, Accuracy: 0.3832, Precision: 0.7060, Recall: 0.6871\n",
            "Validation Loss: 0.6123, Accuracy: 0.2333, Precision: 0.7707, Recall: 0.5970\n",
            "\n",
            "Epoch 14/20\n",
            "Training Loss: 0.4787, Accuracy: 0.4000, Precision: 0.7021, Recall: 0.6607\n",
            "Validation Loss: 0.5710, Accuracy: 0.3250, Precision: 0.7798, Recall: 0.6716\n",
            "\n",
            "Epoch 15/20\n",
            "Training Loss: 0.4754, Accuracy: 0.4000, Precision: 0.6945, Recall: 0.6719\n",
            "Validation Loss: 0.6450, Accuracy: 0.3333, Precision: 0.7538, Recall: 0.7711\n",
            "\n",
            "Epoch 16/20\n",
            "Training Loss: 0.4769, Accuracy: 0.3965, Precision: 0.6785, Recall: 0.6634\n",
            "Validation Loss: 0.5431, Accuracy: 0.3167, Precision: 0.7291, Recall: 0.7662\n",
            "\n",
            "Epoch 17/20\n",
            "Training Loss: 0.4700, Accuracy: 0.3929, Precision: 0.7046, Recall: 0.6686\n",
            "Validation Loss: 0.6213, Accuracy: 0.4083, Precision: 0.7466, Recall: 0.8109\n",
            "\n",
            "Epoch 18/20\n",
            "Training Loss: 0.4721, Accuracy: 0.4106, Precision: 0.7113, Recall: 0.6871\n",
            "Validation Loss: 0.5710, Accuracy: 0.2833, Precision: 0.8019, Recall: 0.6517\n",
            "\n",
            "Epoch 19/20\n",
            "Training Loss: 0.4682, Accuracy: 0.4186, Precision: 0.7109, Recall: 0.6831\n",
            "Validation Loss: 0.6158, Accuracy: 0.2583, Precision: 0.7711, Recall: 0.6716\n",
            "\n",
            "Epoch 20/20\n",
            "Training Loss: 0.4658, Accuracy: 0.4257, Precision: 0.7173, Recall: 0.6798\n",
            "Validation Loss: 0.5662, Accuracy: 0.2917, Precision: 0.7749, Recall: 0.7164\n",
            "\n"
          ]
        }
      ],
      "source": [
        "num_epochs = 20\n",
        "warnings.filterwarnings(\"ignore\", category=UserWarning, module=\"torchio\")\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    all_train_preds = []\n",
        "    all_train_labels = []\n",
        "    for batch in train_loader:\n",
        "        data = batch['image'][tio.DATA].to(device)\n",
        "        labels = torch.tensor(\n",
        "            [batch['abnormal'], batch['acl'], batch['meniscus']],\n",
        "            dtype=torch.float32\n",
        "        ).T.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(data)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item() * data.size(0)\n",
        "\n",
        "        # Collect predictions and labels for metrics\n",
        "        outputs = torch.sigmoid(outputs)\n",
        "        preds = (outputs > 0.5).float()\n",
        "        all_train_preds.append(preds.cpu())\n",
        "        all_train_labels.append(labels.cpu())\n",
        "\n",
        "    # Compute training metrics\n",
        "    all_train_preds = torch.cat(all_train_preds)\n",
        "    all_train_labels = torch.cat(all_train_labels)\n",
        "    train_accuracy = accuracy_score(all_train_labels.numpy(), all_train_preds.numpy())\n",
        "    train_precision = precision_score(all_train_labels.numpy(), all_train_preds.numpy(), average='weighted', zero_division=0)\n",
        "    train_recall = recall_score(all_train_labels.numpy(), all_train_preds.numpy(), average='weighted', zero_division=0)\n",
        "    epoch_loss = running_loss / len(train_dataset)\n",
        "\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs}\")\n",
        "    print(f\"Training Loss: {epoch_loss:.4f}, Accuracy: {train_accuracy:.4f}, Precision: {train_precision:.4f}, Recall: {train_recall:.4f}\")\n",
        "\n",
        "    model.eval()\n",
        "    val_running_loss = 0.0\n",
        "    all_val_preds = []\n",
        "    all_val_labels = []\n",
        "    with torch.no_grad():\n",
        "        for batch in valid_loader:\n",
        "            data = batch['image'][tio.DATA].to(device)\n",
        "            labels = torch.tensor(\n",
        "                [batch['abnormal'], batch['acl'], batch['meniscus']],\n",
        "                dtype=torch.float32\n",
        "            ).T.to(device)\n",
        "\n",
        "            outputs = model(data)\n",
        "            loss = criterion(outputs, labels)\n",
        "            val_running_loss += loss.item() * data.size(0)\n",
        "\n",
        "            # Collect predictions and labels for metrics\n",
        "            outputs = torch.sigmoid(outputs)\n",
        "            preds = (outputs > 0.5).float()\n",
        "            all_val_preds.append(preds.cpu())\n",
        "            all_val_labels.append(labels.cpu())\n",
        "\n",
        "    # Compute validation metrics\n",
        "    all_val_preds = torch.cat(all_val_preds)\n",
        "    all_val_labels = torch.cat(all_val_labels)\n",
        "    val_accuracy = accuracy_score(all_val_labels.numpy(), all_val_preds.numpy())\n",
        "    val_precision = precision_score(all_val_labels.numpy(), all_val_preds.numpy(), average='weighted', zero_division=0)\n",
        "    val_recall = recall_score(all_val_labels.numpy(), all_val_preds.numpy(), average='weighted', zero_division=0)\n",
        "    val_loss = val_running_loss / len(valid_dataset)\n",
        "\n",
        "    print(f\"Validation Loss: {val_loss:.4f}, Accuracy: {val_accuracy:.4f}, Precision: {val_precision:.4f}, Recall: {val_recall:.4f}\\n\")\n",
        "    scheduler.step()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Explanation of 3D-ResNet Results:\n",
        "\n",
        "### **Epochs 1-5**\n",
        "\n",
        "| Epoch | Training Loss | Training Accuracy | Training Precision | Training Recall | Validation Loss | Validation Accuracy | Validation Precision | Validation Recall |\n",
        "|-------|---------------|-------------------|--------------------|------------------|------------------|---------------------|----------------------|--------------------|\n",
        "| 1     | 0.5448        | 0.3690            | 0.6314             | 0.6304           | 1.7998           | 0.2417              | 0.4035               | 0.1741             |\n",
        "| 2     | 0.5310        | 0.3673            | 0.5943             | 0.6192           | 0.6786           | 0.2250              | 0.6074               | 0.4826             |\n",
        "| 3     | 0.5303        | 0.3726            | 0.5861             | 0.6212           | 0.6962           | 0.1833              | 0.5896               | 0.4030             |\n",
        "| 4     | 0.5205        | 0.3690            | 0.6059             | 0.6271           | 0.7724           | 0.3500              | 0.7381               | 0.6915             |\n",
        "| 5     | 0.5133        | 0.3814            | 0.6831             | 0.6469           | 0.6772           | 0.2000              | 0.7362               | 0.5821             |\n",
        "\n",
        "**Observations:**\n",
        "- **Training Metrics:** There's a slight decrease in training loss and a modest increase in training accuracy from Epoch 1 to Epoch 5. Precision and recall show improvement, indicating better performance on the training data.\n",
        "- **Validation Metrics:** Validation loss fluctuates without a clear downward trend, and validation accuracy remains low (~18-35%). Precision and recall are inconsistent, suggesting that the model struggles to generalize beyond the training data.\n",
        "\n",
        "---\n",
        "\n",
        "### **Epochs 6-10**\n",
        "\n",
        "| Epoch | Training Loss | Training Accuracy | Training Precision | Training Recall | Validation Loss | Validation Accuracy | Validation Precision | Validation Recall |\n",
        "|-------|---------------|-------------------|--------------------|------------------|------------------|---------------------|----------------------|--------------------|\n",
        "| 6     | 0.5123        | 0.3708            | 0.6705             | 0.6344           | 0.6924           | 0.2083              | 0.8128               | 0.5274             |\n",
        "| 7     | 0.5073        | 0.3867            | 0.6706             | 0.6489           | 0.7137           | 0.2167              | 0.7282               | 0.6468             |\n",
        "| 8     | 0.5002        | 0.3832            | 0.6522             | 0.6331           | 0.6368           | 0.3167              | 0.7719               | 0.7363             |\n",
        "| 9     | 0.5065        | 0.3796            | 0.6862             | 0.6542           | 0.6742           | 0.2083              | 0.8099               | 0.5423             |\n",
        "| 10    | 0.5021        | 0.3735            | 0.6955             | 0.6449           | 0.6415           | 0.1750              | 0.7418               | 0.5721             |\n",
        "\n",
        "**Observations:**\n",
        "- **Training Metrics:** Training loss continues to decrease slightly, and accuracy improves marginally. Precision shows a positive trend, while recall remains relatively stable.\n",
        "- **Validation Metrics:** Validation loss remains high and varies without consistent improvement. Validation accuracy shows minimal changes, and precision and recall fluctuate, further indicating poor generalization.\n",
        "\n",
        "---\n",
        "\n",
        "### **Epochs 11-15**\n",
        "\n",
        "| Epoch | Training Loss | Training Accuracy | Training Precision | Training Recall | Validation Loss | Validation Accuracy | Validation Precision | Validation Recall |\n",
        "|-------|---------------|-------------------|--------------------|------------------|------------------|---------------------|----------------------|--------------------|\n",
        "| 11    | 0.4836        | 0.3938            | 0.6969             | 0.6798           | 0.5906           | 0.3250              | 0.7765               | 0.6468             |\n",
        "| 12    | 0.4977        | 0.3894            | 0.6772             | 0.6344           | 0.6221           | 0.3583              | 0.7552               | 0.7662             |\n",
        "| 13    | 0.4807        | 0.3832            | 0.7060             | 0.6871           | 0.6123           | 0.2333              | 0.7707               | 0.5970             |\n",
        "| 14    | 0.4787        | 0.4000            | 0.7021             | 0.6607           | 0.5710           | 0.3250              | 0.7798               | 0.6716             |\n",
        "| 15    | 0.4754        | 0.4000            | 0.6945             | 0.6719           | 0.6450           | 0.3333              | 0.7538               | 0.7711             |\n",
        "\n",
        "**Observations:**\n",
        "- **Training Metrics:** There's a slight improvement in training accuracy and a decrease in training loss. Precision and recall remain relatively stable, showing that the model maintains consistent performance on training data.\n",
        "- **Validation Metrics:** Validation loss shows minor fluctuations but doesn't exhibit a clear downward trend. Validation accuracy remains low to moderate (~23-35%), while precision and recall vary, indicating inconsistent performance.\n",
        "\n",
        "---\n",
        "\n",
        "### **Epochs 16-20**\n",
        "\n",
        "| Epoch | Training Loss | Training Accuracy | Training Precision | Training Recall | Validation Loss | Validation Accuracy | Validation Precision | Validation Recall |\n",
        "|-------|---------------|-------------------|--------------------|------------------|------------------|---------------------|----------------------|--------------------|\n",
        "| 16    | 0.4769        | 0.3965            | 0.6785             | 0.6634           | 0.5431           | 0.3167              | 0.7291               | 0.7662             |\n",
        "| 17    | 0.4700        | 0.3929            | 0.7046             | 0.6686           | 0.6213           | 0.4083              | 0.7466               | 0.8109             |\n",
        "| 18    | 0.4721        | 0.4106            | 0.7113             | 0.6871           | 0.5710           | 0.2833              | 0.8019               | 0.6517             |\n",
        "| 19    | 0.4682        | 0.4186            | 0.7109             | 0.6831           | 0.6158           | 0.2583              | 0.7711               | 0.6716             |\n",
        "| 20    | 0.4658        | 0.4257            | 0.7173             | 0.6798           | 0.5662           | 0.2917              | 0.7749               | 0.7164             |\n",
        "\n",
        "**Observations:**\n",
        "- **Training Metrics:** Training loss decreases slightly, and accuracy shows a modest improvement. Precision and recall remain consistent, indicating stable performance on the training set.\n",
        "- **Validation Metrics:** Validation loss experiences minor reductions but remains relatively high. Validation accuracy shows negligible improvement, and precision and recall vary without a clear upward trend. These patterns reinforce the presence of **overfitting**, where the model fails to generalize effectively to validation data despite improving performance on training data.\n",
        "\n",
        "---\n",
        "\n",
        "### **Summary of 3D ResNet Performance**\n",
        "\n",
        "- **Training Performance:**\n",
        "  - **Loss:** Decreases gradually from ~0.5448 to ~0.4658.\n",
        "  - **Accuracy:** Increases from ~37% to ~43%.\n",
        "  - **Precision & Recall:** Fluctuate between ~0.59 to ~0.71, showing inconsistent improvement.\n",
        "\n",
        "- **Validation Performance:**\n",
        "  - **Loss:** Remains high, fluctuating between ~0.54 to ~1.80.\n",
        "  - **Accuracy:** Remains low to moderate, between ~17% to ~41%.\n",
        "  - **Precision & Recall:** Vary significantly, indicating inconsistent model behavior on unseen data.\n",
        "\n",
        "**Conclusion:** The **3D ResNet** model exhibits clear signs of **overfitting**. While there's some improvement in training metrics, the validation performance remains subpar and inconsistent, suggesting that the model struggles to generalize beyond the training dataset.\n",
        "\n",
        "---\n",
        "\n",
        "### **Next Steps: Transitioning to ResNet18**\n",
        "\n",
        "Given the overfitting observed with the 3D ResNet model, we will now **transition to a 3D ResNet18** architecture. **ResNet18** is less complex and has fewer parameters compared to deeper ResNet variants, which can help mitigate overfitting and improve the model's ability to generalize to validation data.\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
