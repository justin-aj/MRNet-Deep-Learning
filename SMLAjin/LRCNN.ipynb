{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "5eafdb6e-0be1-4001-be2e-9bb26b86170a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ajinf\\anaconda3\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ajinf\\anaconda3\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting features for training data...\n",
      "Extracting features for validation data...\n",
      "Training Logistic Regression model...\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 0. 0. 0. 1. 1.\n",
      " 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 1. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 1. 0.\n",
      " 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 1. 0. 0. 1. 1. 0. 1. 1. 1. 1. 0. 1. 0. 1.\n",
      " 1. 1. 0. 1. 0. 1. 0. 0. 0. 1. 0. 1. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Validation Accuracy: 0.44166666666666665\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.44      0.94      0.60       159\n",
      "         1.0       0.50      0.04      0.08       201\n",
      "\n",
      "    accuracy                           0.44       360\n",
      "   macro avg       0.47      0.49      0.34       360\n",
      "weighted avg       0.47      0.44      0.31       360\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ajinf\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from torchvision import models\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Define the dataset class\n",
    "class MRNetDataset(Dataset):\n",
    "    def __init__(self, data_dir, csv_files):\n",
    "        self.data_dir = data_dir\n",
    "        # Load the CSV files and combine them\n",
    "        self.labels = []\n",
    "        for file in csv_files:\n",
    "            temp = pd.read_csv(file, sep=\",\", header=None, names=[\"file_id\", \"label\"])\n",
    "            self.labels.append(temp)\n",
    "        self.labels = pd.concat(self.labels, axis=0)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # Extract file_id and label\n",
    "        file_id = self.labels.iloc[idx][\"file_id\"]\n",
    "        label = self.labels.iloc[idx][\"label\"]\n",
    "        \n",
    "        # Clean and parse file_id\n",
    "        try:\n",
    "            # Remove unexpected characters (e.g., commas) and convert to integer\n",
    "            file_id = int(str(file_id).split(',')[0].strip())\n",
    "        except ValueError:\n",
    "            raise ValueError(f\"File ID '{file_id}' cannot be converted to an integer. Check your labels CSV file.\")\n",
    "        \n",
    "        # Build file path and load .npy file\n",
    "        file_path = os.path.join(self.data_dir, f\"{file_id:04d}.npy\")\n",
    "        if not os.path.exists(file_path):\n",
    "            raise FileNotFoundError(f\"File not found: {file_path}\")\n",
    "        \n",
    "        data = np.load(file_path)\n",
    "        \n",
    "        # Normalize data and add channel dimension\n",
    "        data = (data - np.min(data)) / (np.max(data) - np.min(data))  # Normalize\n",
    "        data = np.expand_dims(data, axis=0)  # Add channel dimension (C, H, W)\n",
    "        \n",
    "        return torch.tensor(data, dtype=torch.float32), torch.tensor(label, dtype=torch.float32)\n",
    "\n",
    "\n",
    "# Feature extraction function\n",
    "def extract_features(data_loader, model):\n",
    "    features, labels = [], []\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for images, targets in data_loader:\n",
    "            images = images.to(device)\n",
    "            outputs = model(images)\n",
    "            features.append(outputs.cpu().numpy())\n",
    "            labels.append(targets.numpy())\n",
    "    return np.vstack(features), np.hstack(labels)\n",
    "\n",
    "# Paths\n",
    "train_axial_dir = r\"C:\\Users\\ajinf\\Documents\\DS 5220\\Projects\\SML-Project\\MRNet-v1.0\\train\\axial\"\n",
    "valid_axial_dir = r\"C:\\Users\\ajinf\\Documents\\DS 5220\\Projects\\SML-Project\\MRNet-v1.0\\valid\\axial\"\n",
    "train_labels_csv_files = [\n",
    "    r\"C:\\Users\\ajinf\\Documents\\DS 5220\\Projects\\SML-Project\\MRNet-v1.0\\train-abnormal.csv\",\n",
    "    r\"C:\\Users\\ajinf\\Documents\\DS 5220\\Projects\\SML-Project\\MRNet-v1.0\\train-acl.csv\",\n",
    "    r\"C:\\Users\\ajinf\\Documents\\DS 5220\\Projects\\SML-Project\\MRNet-v1.0\\train-meniscus.csv\"\n",
    "]\n",
    "valid_labels_csv_files = [\n",
    "    r\"C:\\Users\\ajinf\\Documents\\DS 5220\\Projects\\SML-Project\\MRNet-v1.0\\valid-abnormal.csv\",\n",
    "    r\"C:\\Users\\ajinf\\Documents\\DS 5220\\Projects\\SML-Project\\MRNet-v1.0\\valid-acl.csv\",\n",
    "    r\"C:\\Users\\ajinf\\Documents\\DS 5220\\Projects\\SML-Project\\MRNet-v1.0\\valid-meniscus.csv\"\n",
    "]\n",
    "\n",
    "# Dataset and DataLoader\n",
    "train_dataset = MRNetDataset(train_axial_dir, train_labels_csv_files)\n",
    "valid_dataset = MRNetDataset(valid_axial_dir, valid_labels_csv_files)\n",
    "\n",
    "def resize_images(images, target_height):\n",
    "    batch_size, channels, height, width = images.size()\n",
    "    \n",
    "    # Permute the dimensions to have the height and channel dimensions in the second and third place\n",
    "    images = images.permute(0, 2, 1, 3)  # (batch_size, height, channels, width)\n",
    "    \n",
    "    # Resize the second dimension (height) to the target value\n",
    "    resized_images = F.interpolate(images, size=(target_height, width), mode='bilinear', align_corners=False)\n",
    "    \n",
    "    # Permute back to the original order (batch_size, channels, target_height, width)\n",
    "    resized_images = resized_images.permute(0, 2, 1, 3)\n",
    "    return resized_images\n",
    "    \n",
    "def custom_collate_fn(batch):\n",
    "    # Assuming batch is a list of (image, label) tuples\n",
    "    images, labels = zip(*batch)\n",
    "    images_all = []\n",
    "    for img in images:\n",
    "        resized_images = resize_images(img, 20)\n",
    "        images_all.append(resized_images)\n",
    "        \n",
    "    images = [transforms.Resize((256, 256))(img) for img in images_all]  # Resize all images\n",
    "    images = torch.stack(images, 0)\n",
    "    images = images[:, :, :, :, 0]  # Keep the first element along the last dimension\n",
    "    labels = torch.tensor(labels)  # Adjust as needed for your labels\n",
    "    return images, labels\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, collate_fn=custom_collate_fn, shuffle=True)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=8, collate_fn=custom_collate_fn, shuffle=False)\n",
    "\n",
    "# Load pre-trained CNN (ResNet18)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "cnn_model = models.resnet18(pretrained=True)\n",
    "cnn_model.conv1 = torch.nn.Conv2d(1, cnn_model.conv1.out_channels, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
    "cnn_model.fc = nn.Identity()  # Remove the final classification layer\n",
    "cnn_model = cnn_model.to(device)\n",
    "\n",
    "# Extract features\n",
    "print(\"Extracting features for training data...\")\n",
    "train_features, train_labels = extract_features(train_loader, cnn_model)\n",
    "\n",
    "print(\"Extracting features for validation data...\")\n",
    "valid_features, valid_labels = extract_features(valid_loader, cnn_model)\n",
    "\n",
    "# Train Logistic Regression\n",
    "print(\"Training Logistic Regression model...\")\n",
    "log_reg = LogisticRegression()\n",
    "log_reg.fit(train_features, train_labels)\n",
    "\n",
    "# Evaluate\n",
    "valid_predictions = log_reg.predict(valid_features)\n",
    "\n",
    "print(valid_labels, valid_predictions)\n",
    "print(\"Validation Accuracy:\", accuracy_score(valid_labels, valid_predictions))\n",
    "print(classification_report(valid_labels, valid_predictions))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b83a73d4-5e38-4c55-bd69-0742ff36bd21",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
